* Down
  The main aim is to download large files over proxies that have a cap
  on maximum size of a file that can be downloaded.  This is
  accomplished downloading files part-by-part, i.e., at once, we are
  downloading a file of size smaller than the maximum allowed.  Once
  all the parts are downloaded, these could be combined to get the
  original file.
* What next?
** Native curl library
   Haskell has a curl library implementation.  Currently, the project
   makes use of curl system calls to do the downloading and other
   stuff.  As a modification, the curl library (implemented by Galios
   Inc) could be used instead of the system calls.
** Support for resume
   If ~Ctrl-C~ is pressed, the download stops.  But when the download
   is restarted, it simply ignores the already downloaded parts (or
   parts within parts.)  Somehow, this has to be plugged.
** Support for parallel downloads
   Currently, the program downloads the file one by one.  There is no
   harm in doing this in parallel.
   
   

** Filename
   Currently, the file name static; need to make it better.
